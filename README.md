# Private-LLM-Inference-Optimization-TEE

### 2025
- Sun, Tong, Bowen Jiang, Hailong Lin, et al. “TensorShield: Safeguarding On-Device Inference by Shielding Critical DNN Tensors with TEE.” arXiv:2505.22735. Preprint, arXiv, May 28, 2025. https://doi.org/10.48550/arXiv.2505.22735. (ACM CCS'25)
  - **Code:** [https://github.com/suntong30/TensorShield](https://github.com/suntong30/TensorShield)
- Li, Ding, Ziqi Zhang, Mengyu Yao, Yifeng Cai, Yao Guo, and Xiangqun Chen. “TEESlice : Protecting Sensitive Neural Network Models in Trusted Execution Environments When Attackers Have Pre-Trained Models.” ACM Transactions on Software Engineering and Methodology 34, no. 6 (2025): 1–49. https://doi.org/10.1145/3707453.
- Sun, Yu, Gaojian Xiong, Jianhua Liu, Zheng Liu, and Jian Cui. “TSQP: Safeguarding Real-Time Inference for Quantization Neural Networks on Edge Devices.” 2025 IEEE Symposium on Security and Privacy (SP), May 2025, 2114–32. https://doi.org/10.1109/SP61157.2025.00001.
- Bai, Juyang, Md Hafizul Islam Chowdhuryy, Jingtao Li, Fan Yao, Chaitali Chakrabarti, and Deliang Fan. “Phantom: Privacy-Preserving Deep Neural Network Model Obfuscation in Heterogeneous TEE and GPU System.” 2025, 5565–82. https://www.usenix.org/conference/usenixsecurity25/presentation/bai-juyang.
- Moon, Myungsuk, Minhee Kim, Joonkyo Jung, and Dokyung Song. “ASGARD: Protecting On-Device Deep Neural Networks with Virtualization-Based Trusted Execution Environments.” Paper presented at Network and Distributed System Security Symposium, San Diego, CA, USA. Proceedings 2025 Network and Distributed System Security Symposium, Internet Society, 2025. https://doi.org/10.14722/ndss.2025.240449.








### 2024



- Mishra, Abhijit, Mingda Li, and Soham Deo. “SentinelLMs: Encrypted Input Adaptation and Fine-Tuning of Language Models for Private and Secure Inference.” Proceedings of the AAAI Conference on Artificial Intelligence 38, no. 19 (2024): 21403–11. https://doi.org/10.1609/aaai.v38i19.30136. ![Focus](https://img.shields.io/badge/LLM-blue)
- Li, Qinfeng, Zhiqiang Shen, Zhenghan Qin, et al. “TransLinkGuard: Safeguarding Transformer Models Against Model Stealing in Edge Deployment.” Proceedings of the 32nd ACM International Conference on Multimedia, ACM, October 28, 2024, 3479–88. https://doi.org/10.1145/3664647.3680786. ![Focus](https://img.shields.io/badge/LLM-blue)




- Zhang, Ziqi, Chen Gong, Yifeng Cai, et al. “No Privacy Left Outside: On the (In-)Security of TEE-Shielded DNN Partition for On-Device ML.” 2024 IEEE Symposium on Security and Privacy (SP), IEEE, May 19, 2024, 3327–45. https://doi.org/10.1109/SP54263.2024.00052.
- Zhang, Zheng, Na Wang, Ziqi Zhang, et al. “GroupCover: A Secure, Efficient and Scalable Inference Framework for On-Device Model Protection Based on TEEs.” Proceedings of the 41st International Conference on Machine Learning, PMLR, July 8, 2024, 59992–60003. https://proceedings.mlr.press/v235/zhang24bn.html.
- Liu, Ziyu, Tong Zhou, Yukui Luo, and Xiaolin Xu. “TBNet: A Neural Architectural Defense Framework Facilitating DNN Model Protection in Trusted Execution Environments.” Proceedings of the 61st ACM/IEEE Design Automation Conference, ACM, June 23, 2024, 1–6. https://doi.org/10.1145/3649329.3658251.


### 2023

- Sun, Zhichuang, Ruimin Sun, Changming Liu, Amrita Roy Chowdhury, Long Lu, and Somesh Jha. “ShadowNet: A Secure and Efficient On-Device Model Inference System for Convolutional Neural Networks.” 2023 IEEE Symposium on Security and Privacy (SP), May 2023, 1596–612. https://doi.org/10.1109/SP46215.2023.10179382.
- Zhou, Tong, Yukui Luo, Shaolei Ren, and Xiaolin Xu. “NNSplitter: An Active Defense Solution for DNN Model via Automated Weight Obfuscation.” Proceedings of the 40th International Conference on Machine Learning, PMLR, July 3, 2023, 42614–24. https://proceedings.mlr.press/v202/zhou23h.html.


### 2022


- Shen, Tianxiang, Ji Qi, Jianyu Jiang, et al. “SOTER: Guarding Black-Box Inference for General Neural Networks at the Edge.” 2022, 723–38. https://www.usenix.org/conference/atc22/presentation/shen. (USENIX ATC 22)
- Hou, Jiahui, Huiqi Liu, Yunxin Liu, Yu Wang, Peng-Jun Wan, and Xiang-Yang Li. “Model Protection: Real-Time Privacy-Preserving Inference Service for Model Privacy at the Edge.” IEEE Transactions on Dependable and Secure Computing 19, no. 6 (2022): 4270–84. https://doi.org/10.1109/TDSC.2021.3126315.


### 2021

- Ng, Lucien K. L., Sherman S. M. Chow, Anna P. Y. Woo, Donald P. H. Wong, and Yongjun Zhao. “Goten: GPU-Outsourcing Trusted Execution of Neural Network Training.” Proceedings of the AAAI Conference on Artificial Intelligence 35, no. 17 (2021): 14876–83. https://doi.org/10.1609/aaai.v35i17.17746.
-  Hashemi, Hanieh, Yongqin Wang, and Murali Annavaram. “DarKnight: An Accelerated Framework for Privacy and Integrity Preserving Deep Learning Using Trusted Hardware.” MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture, ACM, October 18, 2021, 212–24. https://doi.org/10.1145/3466752.3480112.



### 2018

- Tramer, Florian, and Dan Boneh. “Slalom: Fast, Verifiable and Private Execution of Neural Networks in Trusted Hardware.” Paper presented at International Conference on Learning Representations. September 27, 2018. https://openreview.net/forum?id=rJVorjCcKQ.





